<h1>NLP Server</h1>

<p>A <a href="http://flask.pocoo.org/">flask</a> based python web server that acts as a REST API for some Natural Language Processing tasks. Written primarily for use in <a href="http://metadatagames.com/">metadatagames</a>.</p>

<p>At the moment, the feature set is small and basic, but I hope to expand on it. Current highlight is the ability to check whether a given input is a <em>possible</em> english word or not. For instance, something like <a href="http://en.wikipedia.org/wiki/Lisa_the_Iconoclast#Embiggen_and_cromulent"><em>embiggen</em></a> or <a href="http://en.wikipedia.org/wiki/Lisa_the_Iconoclast#Embiggen_and_cromulent"><em>cromulent</em></a> are possible english words, as opposed to <em>bdskajb</em>. Rather than relying on a dictionary check for the input, which ignores words that don't appear widely in dictionaries (eg: <em>lol</em>. In fact, some may not even consider this as an English word. But I digress -- this is perhaps not the place to debate on the status of such words), the system here employs a <a href="http://en.wikipedia.org/wiki/Language_model">language model</a> based on letter bigrams to decide whether an input is a possible word. Possible applications here include: system to detect online vanadalism, forbid random keyboard input but accept proper names or anything that could pass as a word, detect <a href="http://en.wikipedia.org/wiki/Loanword">borrowed words</a> in a language, etc.</p>

<p>The server currently works for English, but with an appropriate corpus, it should be extensible to other langauges. Look at the <em>scripts</em> folder for more details on that. The scripts there are stand-alone python scripts and may be used independently of the server.</p>

<p>While the system here works fairly well, my implementation here is not the most excellent one. One day, I'll learn enough stats and re-work some parts.</p>

<p>My thanks to the <a href="http://www.tiltfactor.org/">tiltfactor lab</a> for allowing me to work on this.</p>

<h2>Setup</h2>

<p>Install flask with pip:</p>

<pre><code>sudo  pip install flask
</code></pre>

<p>This will install flask system-wide. If you prefer working with virtual environment, follow the instructions <a href="http://flask.pocoo.org/docs/installation/">here</a>.</p>

<p>For parts of the program to work, you'll need the <a href="http://pythonhosted.org/pyenchant/download.html">PyEnchant</a> library.</p>

<pre><code>sudo pip install pyenchant
</code></pre>

<p>Now run the server:</p>

<pre><code>python run_nlpserver.py
</code></pre>

<p>Go to <a href="http://localhost:8139">http://localhost:8139</a> and you should see a simple welcome message.</p>

<p>Basic configuration is handled from <em>config.py</em> where things like server name and port can be changed. If you are using this in a production environment, set the <em>DEBUG</em> flag to <em>False</em> here. Messages get logged to <em>nlpserver.log</em> file (if you ran it from the same directory as the <em>run_nlpserver.py</em> file, the log file will be right there.) Make sure that you have a symlink pointing to <em>scripts</em> in the <em>nlpserver</em> folder, if you encounter moudle import errors related to the nlp scripts. If you can't form a symlink (eg: on Windows machines), just move the <em>scripts</em> folder inside <em>nlpserver</em>.</p>

<h2>Running the server with mod_wsgi</h2>

<p>If you already have apache running and don't want a separate flask server running, you can install <a href="https://code.google.com/p/modwsgi/">mod_wsgi</a>
For ubuntu/debian, this will suffice:</p>

<pre><code>sudo apt-get install libapache2-mod-wsgi
</code></pre>

<p>After installing, copy the <em>example/nlpserver</em> file to <em>/etc/apache2/sites-enabled</em>. Modify the user and group field, and also the paths to the app. Change the port from 8139 if you want, but make sure to add the line <em>Listen portnumber</em> to <em>/etc/apache2/ports.conf</em>. Also, in the server directory, update the path in the file <em>nlpserver.wsgi</em>. Then enable the site with </p>

<pre><code>sudo a2ensite nlpserver
</code></pre>

<p>Restart apache and you should be good to go. Note that the configuration of servername, port and logfilename is now dependent on the apache config files, and not on <em>config.py</em>.</p>

<p>In case of problems with mod-wsgi: <a href="http://flask.pocoo.org/docs/deploying/mod_wsgi/">http://flask.pocoo.org/docs/deploying/mod_wsgi/</a>. It might also help to set the log level to <em>info</em> in the apache configuration file.</p>

<p>The flask application here can be kept in any folder for which apache has read access, but for security, make sure that apache can't serve static files from that folder.</p>

<h2>Available views (with a mix of linguistics)</h2>

<p>The commandline utility <a href="http://curl.haxx.se/">curl</a> was used for these demonstrations, but anything capable of doing HTTP GET requests will work (meaning all web browsers)</p>

<h4>/possible_wordcheck</h4>

<p>Besides the standard words, accepts anything that looks like a word in the language. For instance, in English, this would accept something like <a href="http://en.wikipedia.org/wiki/Lisa_the_Iconoclast#Embiggen_and_cromulent"><em>cromulent</em></a> or other such neologisms. Also useful for proper nouns that are not necessarily found in a dictionary. Random keyboard input is forbidden straightaway (as long as it does not look like a word, of course) This last functionality works well for input length greater than 3/4 characters, but for some short inputs, it may raise false positives. Since the word-determination here is probabilistic in nature (by default, data based on letter <a href="http://en.wikipedia.org/wiki/Bigram">bigrams</a> is used. Look in the folder <em>scripts/data/possible_wordcheck/data</em>), such results are bound to appear. A valid english word (i.e. something recorded in dictionaries) will always be accepted here though, so no false negatives.</p>

<pre><code>curl http://localhost:8139/possible_wordcheck?input=cromulent
{
  "response": true
}

curl http://localhost:8139/possible_wordcheck?input=Rauner
{
  "response": true
}

curl http://localhost:8139/possible_wordcheck?input=nkjsnd
{
  "response": false
}

curl http://localhost:8139/possible_wordcheck?input=juggernaut
{
  "response": true
}
</code></pre>

<h4>/possible_wordcheck_strict</h4>

<p>Works like <em>possible_wordcheck</em>, but the idea here is to try and completely forbid <em>non-native</em> (or <a href="http://en.wikipedia.org/wiki/Loanword">loan words</a>) in the language. For instance, something like <em>Qatar</em> in English -- majority of English words have <a href="http://english.stackexchange.com/questions/12326/why-is-q-followed-by-a-u">q followed by u</a>. Or consider <em>juggernaut</em>, whose origins lie in <a href="http://en.wikipedia.org/wiki/Sanskrit">Sanskrit</a> (this word has a really colorful <a href="http://www.etymonline.com/index.php?term=juggernaut">etymology</a>, btw). This route would forbid both these words. In contrast, current implementation of <em>possible_wordcheck</em> accepts cases like <em>Qatar</em> and <em>juggernaut</em>. That is, <em>/possible_wordcheck</em> accepts (or tries to accept) all stuff that you are likely to encounter in English, even though they are not true native words. This one is stricter. </p>

<pre><code>curl http://localhost:8139/possible_wordcheck_strict?input=qatar
{
  "response": false
}

curl http://localhost:8139/possible_wordcheck_strict?input=juggernaut
{
  "response": false
}
</code></pre>

<p>But what about something like <a href="http://www.etymonline.com/index.php?term=chandelier"><em>chandelier</em></a>, which was borrowed from <a href="http://en.wikipedia.org/wiki/Old_French">Old French</a> back in the days? There are plenty of words like this in modern-day English though, that ultimately go back to French and Latin, and since words of this nature were abundant in the corpus I used to make the language model, it's impossible to detect them currently. However, using a corpus based on <a href="http://anglish.wikia.com/wiki/Headside">Anglish</a> (maybe something of this nature: <a href="https://groups.google.com/forum/message/raw?msg=alt.language.artificial/ZL4e3fD7eW0/_7p8bKwLJWkJ">Uncleftish Beholding</a>) would perhaps yield such a result, if desired.</p>

<pre><code>curl http://localhost:8139/possible_wordcheck_strict?input=chandelier
{
  "response": true
}
</code></pre>

<p>While the intended use for this is to check words, it works on the sentence level too.
If you are testing just from a browser, you won't have to spearate spaces like I did here. </p>

<pre><code>curl "http://localhost:8139/possible_wordcheck_strict?input=This%20is%20an%20english%20sentence"
{
  "response": true
}

curl "http://localhost:8139/possible_wordcheck_strict?input=yo%20chain%20hoina%20hai%saathi"
{
  "response": false
}

curl "http://localhost:8139/possible_wordcheck_strict?input=quidquid%20latine%20dictum%20sit%20altum%20videtur"
{
  "response": false
}
</code></pre>

<p>The English sentence was accepted, but Nepali and Latin ones were not.</p>

<h4>/borrowcheck</h4>

<p>Same as <em>possible_wordcheck_strict</em>, except that the polarity is reversed. Returns true if input is determined as a borrowed word.</p>

<pre><code>curl http://localhost:8139/borrowcheck?input=juggernaut
{
  "response": false
}
</code></pre>

<p>Note: Since data based on a bigram model is used by default, the program is currently unable to detect words like <em>tsunami</em> as borrowed. The letter sequence <em>ts</em> at the beginning is uncommon for English words, and using the trigram data for letters should detect words of this nature.</p>

<h4>/wordcheck</h4>

<p>Standard dictionary check, using the pyenchant library. If you want certain words to be accepted by the system, just add the word to the file <em>mywords.txt</em> (symlinked in the root folder from <em>scripts/wordcheck</em>) For instance, you could add <em>embiggen</em> to the list and it would be accepted. Note that adding words here will affect <em>/possible_wordcheck</em> (but not <em>/possible_wordcheck_strict</em>) because to catch cases like <em>Qatar</em>, <em>/possible_wordcheck</em> uses the same dictionary check as this one (that procedure only affects false negatives -- things considered not words through the probabilistic method, like <em>Qatar</em> and <em>juggernaut</em>, but that are actually used in English)</p>

<pre><code>curl http://localhost:8139/wordcheck?input=english
{
  "response": true
}

curl http://localhost:8139/wordcheck?input=embiggen
{
  "response": false
}
</code></pre>

<h4>/spellcheck</h4>

<pre><code>curl http://localhost:8139/spellcheck?input=procastination
{
  "response": false
}
</code></pre>

<h4>/spell_suggestions</h4>

<p>This just uses the pyenchant library. If you want to write a spelling corrector from scratch, Peter Norvig has an excellent <a href="http://norvig.com/spell-correct.html">guide</a>.</p>

<pre><code>curl http://localhost:8139/spell_suggestions?input=procastination
{
  "response": [
    "procrastination",
    "procrastinator",
    "procrastinate",
    "prognostication",
    "predestination",
    "preregistration",
    "overextension"
  ]
}
</code></pre>

<h2>Usage</h2>

<p>The available views output data as JSON and thus it provides a language independent solution, should you wish to perform these checks in your program. For instance, in javascript (with jquery), you could do somethings like this:</p>

<pre><code>// ajax call to the nlp api
var word = "cromulent"
$.ajax({
    type: "GET",
    url: "http://localhost:8139/possible_wordcheck",
    timeout: 5000,
    data: { input: word },
    dataType: "json",
    error: function( o ) {
        console.log('error with nlp api');
    }
}).done(function( o ) {
    var is_possible_word = o.response;
    if (!is_possible_word) {
        console.log(word+' is not a word.');
    }
    else {
        console.log(word+' could be a word.');
    }
});
</code></pre>

<p>If you are using python, just import the scripts as a moudule and work from there (<em>nlpserver/views.py</em> does exactly that.)
Each of the scripts in the folder <em>scripts</em> can be run on their own from the commandline, so a third way to use this collection would be to parse their shell output.</p>

<p>By <a href="https://github.com/anupdhml">Anup M. Dhamala</a>, anupdhml at gmail dot com</p>
